{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfYaD/otqKmAIAFQpQa3U1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khietvuarong/Coding-Exercise---Prompt-Engineering/blob/main/MinhKhietLe_Coding_Exercise_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# INSTALL DEPENDENCY\n",
        "# -------------------------------\n",
        "!pip install -q google-generativeai"
      ],
      "metadata": {
        "id": "hrtA48WoR2FI"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "n7GTStBNMVbi",
        "outputId": "56cb1e2d-f94b-4ff3-b6ea-45358e9db528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Checking Gemini API connection...\n",
            "\n",
            "‚úÖ Gemini API Connected Successfully!\n",
            "üöÄ Using model: models/gemini-2.5-flash\n",
            "\n",
            "=== ü§ñ Customer Support AI (Gemini) ===\n",
            "\n",
            "Customer: Hello\n",
            "\n",
            "[Step 1] Classifying issue...\n",
            "‚úî Category: Other\n",
            "\n",
            "[Step 2] Gathering more information...\n",
            "‚úî Follow-up Question:\n",
            "Hello! How may I assist you today?\n",
            "\n",
            "Customer Additional Info: 2\n",
            "\n",
            "[Step 3] Generating solution...\n",
            "‚úî Proposed Solution:\n",
            "Here's a step-by-step solution:\n",
            "\n",
            "*   Hello there! We received your message and are ready to help, but we'll need a bit more information to understand your request.\n",
            "*   Could you please tell us more about what you need assistance with, or what the number \"2\" refers to?\n",
            "*   Once we have a clearer idea of your query, we'll be happy to provide a complete solution.\n",
            "\n",
            "[Step 4] Checking escalation rule...\n",
            "‚úî Escalation Decision: NO ESCALATION\n",
            "\n",
            "=== ‚úÖ End of Support Flow ===\n"
          ]
        }
      ],
      "source": [
        "# ======================================\n",
        "# Exercise 1 ‚Äì Prompt Chaining\n",
        "# Customer Support AI (Gemini)\n",
        "# With Animated Typing + API Check\n",
        "# ======================================\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import threading\n",
        "import time\n",
        "import sys\n",
        "\n",
        "# --------------------------------------\n",
        "# Configure API\n",
        "# --------------------------------------\n",
        "api_key = userdata.get('Ex1SecretKey')\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "print(\"üîç Checking Gemini API connection...\\n\")\n",
        "\n",
        "available_models = []\n",
        "\n",
        "for m in genai.list_models():\n",
        "    if \"generateContent\" in m.supported_generation_methods:\n",
        "        available_models.append(m.name)\n",
        "\n",
        "if not available_models:\n",
        "    print(\"‚ùå No compatible Gemini models found.\")\n",
        "    raise Exception(\"No working Gemini models available.\")\n",
        "else:\n",
        "    model_name = available_models[0]\n",
        "    print(\"‚úÖ Gemini API Connected Successfully!\")\n",
        "    print(\"üöÄ Using model:\", model_name)\n",
        "\n",
        "model = genai.GenerativeModel(model_name)\n",
        "\n",
        "\n",
        "# --------------------------------------\n",
        "# Typing Animation\n",
        "# --------------------------------------\n",
        "def typing_animation(stop_event):\n",
        "    dots = 0\n",
        "    while not stop_event.is_set():\n",
        "        print(\"\\rü§ñ \" + \".\" * dots + \"   \", end=\"\")\n",
        "        sys.stdout.flush()\n",
        "        dots = (dots + 1) % 4\n",
        "        time.sleep(0.5)\n",
        "    print(\"\\r\" + \" \" * 30 + \"\\r\", end=\"\")  # clear line\n",
        "\n",
        "\n",
        "# --------------------------------------\n",
        "# Gemini Call Wrapper\n",
        "# --------------------------------------\n",
        "def ask_gemini(prompt):\n",
        "    stop_event = threading.Event()\n",
        "    t = threading.Thread(target=typing_animation, args=(stop_event,))\n",
        "    t.start()\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        result = response.text.strip()\n",
        "    finally:\n",
        "        stop_event.set()\n",
        "        t.join()\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "# --------------------------------------\n",
        "# STEP 1: Classify Issue\n",
        "# --------------------------------------\n",
        "def classify_issue(customer_message):\n",
        "    prompt = f\"\"\"\n",
        "Classify the issue into ONE category:\n",
        "Billing\n",
        "Technical Support\n",
        "Account Access\n",
        "Product Information\n",
        "Complaint\n",
        "Other\n",
        "\n",
        "Return ONLY the category name.\n",
        "\n",
        "Customer:\n",
        "{customer_message}\n",
        "\"\"\"\n",
        "    return ask_gemini(prompt)\n",
        "\n",
        "\n",
        "# --------------------------------------\n",
        "# STEP 2: Gather Info\n",
        "# --------------------------------------\n",
        "def gather_info(issue_category, customer_message):\n",
        "    prompt = f\"\"\"\n",
        "Issue category: {issue_category}\n",
        "\n",
        "Ask ONE follow-up question.\n",
        "Do NOT provide solution yet.\n",
        "Max 2 sentences.\n",
        "Be professional and polite.\n",
        "\n",
        "Customer message:\n",
        "{customer_message}\n",
        "\"\"\"\n",
        "    return ask_gemini(prompt)\n",
        "\n",
        "\n",
        "# --------------------------------------\n",
        "# STEP 3: Propose Solution\n",
        "# --------------------------------------\n",
        "def propose_solution(issue_category, customer_message, additional_info):\n",
        "    prompt = f\"\"\"\n",
        "Issue category: {issue_category}\n",
        "\n",
        "Customer message:\n",
        "{customer_message}\n",
        "\n",
        "Additional info:\n",
        "{additional_info}\n",
        "\n",
        "Provide a clear step-by-step solution.\n",
        "- Max 5 bullet points\n",
        "- Be empathetic\n",
        "- Use concise bullets\n",
        "\"\"\"\n",
        "    return ask_gemini(prompt)\n",
        "\n",
        "\n",
        "# --------------------------------------\n",
        "# STEP 4: Escalation\n",
        "# --------------------------------------\n",
        "def escalation_decision(issue_category, solution_text):\n",
        "    prompt = f\"\"\"\n",
        "Issue category: {issue_category}\n",
        "\n",
        "Solution:\n",
        "{solution_text}\n",
        "\n",
        "Return ONLY:\n",
        "ESCALATE\n",
        "or\n",
        "NO ESCALATION\n",
        "\n",
        "Escalate if:\n",
        "- refund over $100\n",
        "- customer angry\n",
        "- tech issue unresolved\n",
        "\"\"\"\n",
        "    return ask_gemini(prompt)\n",
        "\n",
        "\n",
        "# ======================================\n",
        "# FULL HUMAN-INPUT FLOW\n",
        "# ======================================\n",
        "\n",
        "print(\"\\n=== ü§ñ Customer Support AI (Gemini) ===\\n\")\n",
        "\n",
        "customer_input = input(\"Customer: \")\n",
        "\n",
        "# Step 1\n",
        "print(\"\\n[Step 1] Classifying issue...\")\n",
        "category = classify_issue(customer_input)\n",
        "print(\"‚úî Category:\", category)\n",
        "\n",
        "# Step 2\n",
        "print(\"\\n[Step 2] Gathering more information...\")\n",
        "followup = gather_info(category, customer_input)\n",
        "print(\"‚úî Follow-up Question:\")\n",
        "print(followup)\n",
        "\n",
        "# Human reply\n",
        "additional_info = input(\"\\nCustomer Additional Info: \")\n",
        "\n",
        "# Step 3\n",
        "print(\"\\n[Step 3] Generating solution...\")\n",
        "solution = propose_solution(category, customer_input, additional_info)\n",
        "print(\"‚úî Proposed Solution:\")\n",
        "print(solution)\n",
        "\n",
        "# Step 4\n",
        "print(\"\\n[Step 4] Checking escalation rule...\")\n",
        "decision = escalation_decision(category, solution)\n",
        "print(\"‚úî Escalation Decision:\", decision)\n",
        "\n",
        "print(\"\\n=== ‚úÖ End of Support Flow ===\")"
      ]
    }
  ]
}